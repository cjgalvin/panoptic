{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import os.path\n",
    "import re\n",
    "import sys\n",
    "#import r\"C:\\Users\\andor.neo\\Desktop\\casey\\ml_ai\\models-master\\research\\deeplab\\datasets\\cityscapes\\build_data.py\"\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityscapes_root = r\"C:\\Users\\andor.neo\\Desktop\\casey\\ml_ai\\models-master\\research\\deeplab\\datasets\\cityscapes\"\n",
    "\n",
    "output_dir = r\"C:\\Users\\andor.neo\\Desktop\\casey\\ml_ai\\models-master\\research\\deeplab\\datasets\\cityscapes\\tfrecord\"\n",
    "\n",
    "_NUM_SHARDS = 10\n",
    "\n",
    "_FOLDERS_MAP = {\n",
    "    'image': 'leftImg8bit',\n",
    "    'label': 'gtFine',\n",
    "}\n",
    "\n",
    "_POSTFIX_MAP = {\n",
    "    'image': '_leftImg8bit',\n",
    "    'label': '_gtFine_labelTrainIds',\n",
    "}\n",
    "\n",
    "_DATA_FORMAT_MAP = {\n",
    "    'image': 'png',\n",
    "    'label': 'png',\n",
    "}\n",
    "\n",
    "# Image file pattern.\n",
    "_IMAGE_FILENAME_RE = re.compile('(.+)' + _POSTFIX_MAP['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_files(data, dataset_split):\n",
    "    pattern = '*%s.%s' % (_POSTFIX_MAP[data], _DATA_FORMAT_MAP[data])\n",
    "    search_files = os.path.join(\n",
    "      cityscapes_root, _FOLDERS_MAP[data], dataset_split, '*', pattern)\n",
    "    filenames = glob.glob(search_files)\n",
    "    return sorted(filenames)\n",
    "\n",
    "_get_files(\"label\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_dataset(dataset_split):\n",
    "    image_files = _get_files('image', dataset_split)\n",
    "    label_files = _get_files('label', dataset_split)\n",
    "\n",
    "    num_images = len(image_files)\n",
    "    num_per_shard = int(math.ceil(num_images / float(_NUM_SHARDS)))\n",
    "\n",
    "    image_reader = ImageReader('png', channels=3)#build_data.ImageReader('png', channels=3)\n",
    "    label_reader = ImageReader('png', channels=1)#build_data.ImageReader('png', channels=1)\n",
    "    \n",
    "    for shard_id in range(_NUM_SHARDS):\n",
    "        shard_filename = '%s-%05d-of-%05d.tfrecord' % (\n",
    "            dataset_split, shard_id, _NUM_SHARDS)\n",
    "        output_filename = os.path.join(output_dir, shard_filename)\n",
    "        with tf.python_io.TFRecordWriter(output_filename) as tfrecord_writer:\n",
    "            start_idx = shard_id * num_per_shard\n",
    "            end_idx = min((shard_id + 1) * num_per_shard, num_images)\n",
    "            for i in range(start_idx, end_idx):\n",
    "                sys.stdout.write('\\r>> Converting image %d/%d shard %d' % (\n",
    "                i + 1, num_images, shard_id))\n",
    "                sys.stdout.flush()\n",
    "                # Read the image.\n",
    "                image_data = tf.gfile.FastGFile(image_files[i], 'rb').read()\n",
    "                height, width = image_reader.read_image_dims(image_data)\n",
    "                # Read the semantic segmentation annotation.\n",
    "                seg_data = tf.gfile.FastGFile(label_files[i], 'rb').read()\n",
    "                seg_height, seg_width = label_reader.read_image_dims(seg_data)\n",
    "                if height != seg_height or width != seg_width:\n",
    "                    raise RuntimeError('Shape mismatched between image and label.')\n",
    "                # Convert to tf example.\n",
    "                re_match = _IMAGE_FILENAME_RE.search(image_files[i])\n",
    "                if re_match is None:\n",
    "                    raise RuntimeError('Invalid image filename: ' + image_files[i])\n",
    "                filename = os.path.basename(re_match.group(1))\n",
    "                example = image_seg_to_tfexample(\n",
    "                    image_data, filename, height, width, seg_data)\n",
    "                tfrecord_writer.write(example.SerializeToString())\n",
    "        sys.stdout.write('\\n')\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 298/2975 shard 0\n",
      ">> Converting image 596/2975 shard 1\n",
      ">> Converting image 894/2975 shard 2\n",
      ">> Converting image 1192/2975 shard 3\n",
      ">> Converting image 1490/2975 shard 4\n",
      ">> Converting image 1788/2975 shard 5\n",
      ">> Converting image 2086/2975 shard 6\n",
      ">> Converting image 2384/2975 shard 7\n",
      ">> Converting image 2682/2975 shard 8\n",
      ">> Converting image 2975/2975 shard 9\n"
     ]
    }
   ],
   "source": [
    "_convert_dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 50/500 shard 0\n",
      ">> Converting image 100/500 shard 1\n",
      ">> Converting image 150/500 shard 2\n",
      ">> Converting image 200/500 shard 3\n",
      ">> Converting image 250/500 shard 4\n",
      ">> Converting image 300/500 shard 5\n",
      ">> Converting image 350/500 shard 6\n",
      ">> Converting image 400/500 shard 7\n",
      ">> Converting image 450/500 shard 8\n",
      ">> Converting image 500/500 shard 9\n"
     ]
    }
   ],
   "source": [
    "_convert_dataset('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Contains common utility functions and classes for building dataset.\n",
    "\n",
    "This script contains utility functions and classes to converts dataset to\n",
    "TFRecord file format with Example protos.\n",
    "\n",
    "The Example proto contains the following fields:\n",
    "\n",
    "  image/encoded: encoded image content.\n",
    "  image/filename: image filename.\n",
    "  image/format: image file format.\n",
    "  image/height: image height.\n",
    "  image/width: image width.\n",
    "  image/channels: image channels.\n",
    "  image/segmentation/class/encoded: encoded semantic segmentation content.\n",
    "  image/segmentation/class/format: semantic segmentation file format.\n",
    "\"\"\"\n",
    "import collections\n",
    "import six\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "#tf.app.flags.DEFINE_enum('image_format', 'png', ['jpg', 'jpeg', 'png'],'Image format.')\n",
    "\n",
    "#Added by Casey\n",
    "image_format = \"png\"\n",
    "\n",
    "#tf.app.flags.DEFINE_enum('label_format', 'png', ['png'], 'Segmentation label format.')\n",
    "label_format = \"png\"\n",
    "\n",
    "# A map from image format to expected data format.\n",
    "_IMAGE_FORMAT_MAP = {'jpg': 'jpeg', 'jpeg': 'jpeg', 'png': 'png'}\n",
    "\n",
    "\n",
    "class ImageReader(object):\n",
    "  \"\"\"Helper class that provides TensorFlow image coding utilities.\"\"\"\n",
    "\n",
    "  def __init__(self, image_format='jpeg', channels=3):\n",
    "    \"\"\"Class constructor.\n",
    "\n",
    "    Args:\n",
    "      image_format: Image format. Only 'jpeg', 'jpg', or 'png' are supported.\n",
    "      channels: Image channels.\n",
    "    \"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "      self._decode_data = tf.placeholder(dtype=tf.string)\n",
    "      self._image_format = image_format\n",
    "      self._session = tf.Session()\n",
    "      if self._image_format in ('jpeg', 'jpg'):\n",
    "        self._decode = tf.image.decode_jpeg(self._decode_data,\n",
    "                                            channels=channels)\n",
    "      elif self._image_format == 'png':\n",
    "        self._decode = tf.image.decode_png(self._decode_data, channels=channels)\n",
    "\n",
    "  def read_image_dims(self, image_data):\n",
    "    \"\"\"Reads the image dimensions.\n",
    "\n",
    "    Args:\n",
    "      image_data: string of image data.\n",
    "\n",
    "    Returns:\n",
    "      image_height and image_width.\n",
    "    \"\"\"\n",
    "    image = self.decode_image(image_data)\n",
    "    return image.shape[:2]\n",
    "\n",
    "  def decode_image(self, image_data):\n",
    "    \"\"\"Decodes the image data string.\n",
    "\n",
    "    Args:\n",
    "      image_data: string of image data.\n",
    "\n",
    "    Returns:\n",
    "      Decoded image data.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: Value of image channels not supported.\n",
    "    \"\"\"\n",
    "    image = self._session.run(self._decode, feed_dict={self._decode_data: image_data})\n",
    "    if len(image.shape) != 3 or image.shape[2] not in (1, 3):\n",
    "      raise ValueError('The image channels not supported.')\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def _int64_list_feature(values):\n",
    "  \"\"\"Returns a TF-Feature of int64_list.\n",
    "\n",
    "  Args:\n",
    "    values: A scalar or list of values.\n",
    "\n",
    "  Returns:\n",
    "    A TF-Feature.\n",
    "  \"\"\"\n",
    "  if not isinstance(values, collections.Iterable):\n",
    "    values = [values]\n",
    "\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "\n",
    "\n",
    "def _bytes_list_feature(values):\n",
    "  \"\"\"Returns a TF-Feature of bytes.\n",
    "\n",
    "  Args:\n",
    "    values: A string.\n",
    "\n",
    "  Returns:\n",
    "    A TF-Feature.\n",
    "  \"\"\"\n",
    "  def norm2bytes(value):\n",
    "    return value.encode() if isinstance(value, str) and six.PY3 else value\n",
    "\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[norm2bytes(values)]))\n",
    "\n",
    "\n",
    "def image_seg_to_tfexample(image_data, filename, height, width, seg_data):\n",
    "  \"\"\"Converts one image/segmentation pair to tf example.\n",
    "\n",
    "  Args:\n",
    "    image_data: string of image data.\n",
    "    filename: image filename.\n",
    "    height: image height.\n",
    "    width: image width.\n",
    "    seg_data: string of semantic segmentation data.\n",
    "\n",
    "  Returns:\n",
    "    tf example of one image/segmentation pair.\n",
    "  \"\"\"\n",
    "  return tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/encoded': _bytes_list_feature(image_data),\n",
    "      'image/filename': _bytes_list_feature(filename),\n",
    "      'image/format': _bytes_list_feature(_IMAGE_FORMAT_MAP[image_format]),\n",
    "      'image/height': _int64_list_feature(height),\n",
    "      'image/width': _int64_list_feature(width),\n",
    "      'image/channels': _int64_list_feature(3),\n",
    "      'image/segmentation/class/encoded': (_bytes_list_feature(seg_data)),\n",
    "      'image/segmentation/class/format': _bytes_list_feature(label_format),\n",
    "  }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
